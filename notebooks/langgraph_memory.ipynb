{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b827943",
   "metadata": {},
   "source": [
    "# Adding and Managing Memory in LangGraph\n",
    "\n",
    "Don't have a specific tutorial to go through on this one, so I will just grab information from multiple articles and documents in langchain-ai github."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae49c151",
   "metadata": {},
   "source": [
    "## Basic Chatbot\n",
    "Need something basic in order to add memory to track.\n",
    "\n",
    "Using Harish Neel's video series to walk through this for the first time.\n",
    "YouTube video #25 of the series [here](https://www.youtube.com/watch?v=KU_FDwwL5_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2e05d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, add_messages, END\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"ollama:qwen2.5:32b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "765685b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicChatState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d531441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state:BasicChatState):\n",
    "    return {\n",
    "        \"messages\": [llm.invoke(state[\"messages\"])]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0bf491",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(BasicChatState)\n",
    "\n",
    "graph.add_node(\"chatbot\", chatbot)\n",
    "graph.set_entry_point(\"chatbot\")\n",
    "graph.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44931ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7a46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3370fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_greeting = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Hi! i am Tom\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = app.invoke(input_greeting)\n",
    "print(\"Bot:\", response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f332d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_question = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"what's my name?\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = app.invoke(input)\n",
    "print(\"Bot:\", response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37a08ce",
   "metadata": {},
   "source": [
    "## Add tools\n",
    "\n",
    "Video #26 found [here](https://www.youtube.com/watch?v=FYxvh5YQniQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c05a6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "search_tool = TavilySearch(max_results=2)\n",
    "tools = [search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c06699",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool.invoke(\"What's a node in LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d3194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_with_tools(state:BasicChatState):\n",
    "    return {\n",
    "        \"messages\": [llm_with_tools.invoke(state[\"messages\"])]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96011b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tools_router(state:BasicChatState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    # Check if last message is a tool call attribute\n",
    "    if (hasattr(last_message, \"tool_calls\") and len(last_message.tool_calls) > 0):\n",
    "        return \"tool_node\"\n",
    "    else:\n",
    "        return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b48663b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tools_node = ToolNode(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed33f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "graph_with_tools = StateGraph(BasicChatState)\n",
    "\n",
    "graph_with_tools.add_node(\"chatbot\", chatbot_with_tools)\n",
    "graph_with_tools.add_node(\"tools_node\", tools_node)\n",
    "graph_with_tools.set_entry_point(\"chatbot\")\n",
    "\n",
    "graph_with_tools.add_conditional_edges(\"chatbot\", tools_condition, {\"tools\": \"tools_node\", END: END})\n",
    "graph_with_tools.add_edge(\"tools_node\", \"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523c883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_with_tools = graph_with_tools.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b699f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app_with_tools.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9545ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_greeting = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Hi! i am Tom\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = app_with_tools.invoke(input_greeting)\n",
    "print(\"Bot:\", response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4e8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tool_question = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What's a node in LangGraph?\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = app_with_tools.invoke(input_tool_question)\n",
    "print(\"Bot:\", response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd35cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17acd549",
   "metadata": {},
   "source": [
    "## With Memory\n",
    "- Harish Video #27 found [here](https://www.youtube.com/watch?v=QTaou6alCL0)\n",
    "- Official documentation from LangChain-ai [here](https://langchain-ai.github.io/langgraph/tutorials/get-started/3-add-memory/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4946bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "app_with_memory = graph_with_tools.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0835c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app_with_memory.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a642e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d663ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Hello! I'm Tom\"\n",
    "\n",
    "events = app_with_memory.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d126a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Do you remember my name?\"\n",
    "\n",
    "events = app_with_memory.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a8e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = app_with_memory.get_state(config=config)\n",
    "\n",
    "for message in messages.values[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4235e72",
   "metadata": {},
   "source": [
    "## With SqliteSaver Checkpointer\n",
    "Video #28 found [here](https://www.youtube.com/watch?v=xK8g1A5Plvk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db5b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"checkpoints.sqlite\", check_same_thread=False)\n",
    "memory = SqliteSaver(conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_with_sqlite = graph_with_tools.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdb8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_sqlite = {\"configurable\": {\"thread_id\": \"2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2286664",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Hello! I'm Tom\"\n",
    "\n",
    "events = app_with_sqlite.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config_sqlite,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2483007e",
   "metadata": {},
   "source": [
    "## Add Human-in-the-loop controls\n",
    "- Harish videos: [29](https://www.youtube.com/watch?v=UOSMnDOC9T0) and [30](https://www.youtube.com/watch?v=9JHMLBQzU3s)\n",
    "- LangChain-ai documentation: [4-human-in-the-loop](https://langchain-ai.github.io/langgraph/tutorials/get-started/4-human-in-the-loop/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "@tool \n",
    "def human_assistance(query: str) -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt({\"query\": query})\n",
    "    return human_response[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bcdcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb96052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_with_interrupt(state:BasicChatState):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # because we will be interrupting during tool execution\n",
    "    # we disable parallel tool calling to avoid repeating any\n",
    "    # tool invocations when we resume\n",
    "    assert len(message.tool_calls) <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(BasicChatState)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot_with_interrupt)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\", \n",
    "    tools_condition\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
